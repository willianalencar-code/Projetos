import streamlit as st
import duckdb
from huggingface_hub import hf_hub_download
import pandas as pd
import tempfile
from datetime import datetime, timedelta
import pyarrow.parquet as pq
import warnings

warnings.filterwarnings('ignore')

# ==========================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ==========================================
st.set_page_config(
    page_title="üîç Segmenta√ß√£o de Clientes",
    layout="wide",
    page_icon="üë•",
    initial_sidebar_state="expanded"
)

# ==========================================
# ESTILO CSS
# ==========================================
st.markdown("""
<style>
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 4px solid #3B82F6;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        margin-bottom: 1rem;
    }
    
    .filter-card {
        background: #F8FAFC;
        padding: 1.5rem;
        border-radius: 12px;
        border: 1px solid #E2E8F0;
        margin-bottom: 1rem;
    }
    
    .warning-box {
        background-color: #FEF3C7;
        border-left: 4px solid #F59E0B;
        padding: 1rem;
        border-radius: 4px;
        margin: 1rem 0;
    }
    
    .big-metric {
        font-size: 2.5rem !important;
        font-weight: 700 !important;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: #64748B;
        margin-bottom: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# FUN√á√ïES CACHE
# ==========================================
@st.cache_data(show_spinner=False, ttl=3600)
def get_dataset_info():
    """Obt√©m informa√ß√µes do dataset de forma eficiente"""
    try:
        token = st.secrets.get("HF_TOKEN", "")
        caminho_local = hf_hub_download(
            repo_id="WillianAlencar/SegmentacaoClientes",
            filename="dataset.parquet",
            repo_type="dataset",
            token=token if token else None
        )
        
        # Contagem via metadados
        parquet_file = pq.ParquetFile(caminho_local)
        num_rows = parquet_file.metadata.num_rows
        
        # Carrega amostra para an√°lise
        con = duckdb.connect(database=':memory:')
        
        # Amostra para an√°lise
        sample_query = f"""
        SELECT DISTINCT categoria, setor
        FROM read_parquet('{caminho_local}')
        WHERE categoria IS NOT NULL AND setor IS NOT NULL
        LIMIT 100
        """
        
        sample_df = con.execute(sample_query).df()
        
        # Informa√ß√µes b√°sicas
        categorias = sample_df['categoria'].dropna().unique().tolist()
        setores = sample_df['setor'].dropna().unique().tolist()
        
        # Datas min/max para todos os campos de data
        dates_query = f"""
        SELECT 
            MIN(data_ultima_visita) as min_visita,
            MAX(data_ultima_visita) as max_visita,
            MIN(data_ultima_compra) as min_compra,
            MAX(data_ultima_compra) as max_compra,
            MIN(data_cadastro) as min_cadastro,
            MAX(data_cadastro) as max_cadastro
        FROM read_parquet('{caminho_local}')
        """
        
        dates_df = con.execute(dates_query).df()
        
        # Verifica quais campos existem no dataset
        try:
            schema_query = f"DESCRIBE SELECT * FROM read_parquet('{caminho_local}') LIMIT 1"
            columns_df = con.execute(schema_query).df()
            available_columns = columns_df['column_name'].values.tolist()
            has_flg_premium = 'flg_premium_ativo' in available_columns
            has_flg_funcionario = 'flg_funcionario' in available_columns
        except:
            has_flg_premium = False
            has_flg_funcionario = False
            available_columns = []
        
        con.close()
        
        return {
            'caminho': caminho_local,
            'num_rows': num_rows,
            'categorias': sorted(categorias),
            'setores': sorted(setores),
            'available_columns': available_columns,
            'min_visita': dates_df['min_visita'].iloc[0] if not dates_df.empty else pd.Timestamp('2020-01-01'),
            'max_visita': dates_df['max_visita'].iloc[0] if not dates_df.empty else pd.Timestamp.now(),
            'min_compra': dates_df['min_compra'].iloc[0] if not dates_df.empty else pd.Timestamp('2020-01-01'),
            'max_compra': dates_df['max_compra'].iloc[0] if not dates_df.empty else pd.Timestamp.now(),
            'min_cadastro': dates_df['min_cadastro'].iloc[0] if not dates_df.empty else pd.Timestamp('2020-01-01'),
            'max_cadastro': dates_df['max_cadastro'].iloc[0] if not dates_df.empty else pd.Timestamp.now(),
            'has_flg_premium': has_flg_premium,
            'has_flg_funcionario': has_flg_funcionario
        }
        
    except Exception as e:
        st.error(f"Erro de conex√£o: {e}")
        return None

# ==========================================
# CABE√áALHO
# ==========================================
st.markdown("# üë• Segmenta√ß√£o de Clientes")
st.markdown("**Filtre e exporte sua base de clientes**")

# ==========================================
# CARREGAMENTO DOS DADOS
# ==========================================
with st.spinner("üì¶ Carregando informa√ß√µes..."):
    dataset_info = get_dataset_info()

if not dataset_info:
    st.error("‚ùå N√£o foi poss√≠vel carregar os dados. Verifique sua conex√£o.")
    st.stop()

# ==========================================
# SE√á√ÉO DE FILTROS - SIDEBAR
# ==========================================
with st.sidebar:
    st.markdown("### üîç Filtros Avan√ßados")
    
    with st.container():
        st.markdown('<div class="filter-card">', unsafe_allow_html=True)
        st.markdown("**Filtros Principais**")
        
        # Busca por ID
        id_busca = st.text_input("Buscar Cliente (ID)", 
                                 placeholder="Digite o member_pk...")
        
        # Categorias
        cat_sel = st.multiselect("Categorias", 
                                dataset_info['categorias'],
                                placeholder="Selecione categorias...")
        
        # Setores
        setor_sel = st.multiselect("Setores", 
                                  dataset_info['setores'],
                                  placeholder="Selecione setores...")
        
        # Filtro para clientes sem compra
        apenas_sem_compra = st.checkbox("Apenas clientes sem compra", value=False)
        
        # NOVO FILTRO: Funcion√°rios
        if dataset_info['has_flg_funcionario']:
            # Op√ß√µes para filtro de funcion√°rios
            filtro_funcionarios = st.radio(
                "Filtro de Funcion√°rios:",
                ["Todos", "Apenas funcion√°rios", "Excluir funcion√°rios"],
                index=0,
                key="filtro_funcionarios"
            )
        else:
            filtro_funcionarios = "Todos"
            st.caption("‚ÑπÔ∏è Campo 'flg_funcionario' n√£o dispon√≠vel no dataset")
        
        # FILTRO: Usu√°rios premium ativos
        if dataset_info['has_flg_premium']:
            # Nova op√ß√£o: filtrar apenas premium ativos
            apenas_premium = st.checkbox("Apenas usu√°rios premium ativos", value=False)
            
            # Mant√©m a op√ß√£o antiga para compatibilidade
            excluir_premium = st.checkbox("Excluir clientes premium", value=False)
            
            # Valida√ß√£o de filtros contradit√≥rios
            if apenas_premium and excluir_premium:
                st.warning("‚ö†Ô∏è Selecione apenas uma op√ß√£o de filtro premium")
        else:
            apenas_premium = False
            excluir_premium = False
            st.caption("‚ÑπÔ∏è Campo 'flg_premium_ativo' n√£o dispon√≠vel no dataset")
            
        st.markdown('</div>', unsafe_allow_html=True)
    
    with st.container():
        st.markdown('<div class="filter-card">', unsafe_allow_html=True)
        st.markdown("**Filtros de Data**")
        
        # Data de Cadastro
        st.markdown("**Data de Cadastro**")
        usar_cadastro = st.toggle("Ativar filtro de cadastro", value=False, key="toggle_cadastro")
        
        if usar_cadastro:
            col_cad1, col_cad2 = st.columns(2)
            with col_cad1:
                data_inicio_cadastro = st.date_input("De", 
                                                    value=dataset_info['min_cadastro'].date(),
                                                    key="inicio_cadastro",
                                                    label_visibility="collapsed")
            with col_cad2:
                data_fim_cadastro = st.date_input("At√©", 
                                                 value=dataset_info['max_cadastro'].date(),
                                                 key="fim_cadastro",
                                                 label_visibility="collapsed")
        else:
            data_inicio_cadastro = None
            data_fim_cadastro = None
        
        # Data de Visita
        st.markdown("**√öltima Visita**")
        col1, col2 = st.columns(2)
        with col1:
            data_inicio_visita = st.date_input("De", 
                                              value=dataset_info['min_visita'].date(),
                                              key="inicio_visita",
                                              label_visibility="collapsed")
        with col2:
            data_fim_visita = st.date_input("At√©", 
                                           value=dataset_info['max_visita'].date(),
                                           key="fim_visita",
                                           label_visibility="collapsed")
        
        # Data de Compra
        st.markdown("**√öltima Compra**")
        usar_compra = st.toggle("Ativar filtro", value=False, key="toggle_compra")
        
        if usar_compra:
            col3, col4 = st.columns(2)
            with col3:
                data_inicio_compra = st.date_input("De", 
                                                  value=dataset_info['min_compra'].date(),
                                                  key="inicio_compra",
                                                  label_visibility="collapsed")
            with col4:
                data_fim_compra = st.date_input("At√©", 
                                               value=dataset_info['max_compra'].date(),
                                               key="fim_compra",
                                               label_visibility="collapsed")
        else:
            data_inicio_compra = None
            data_fim_compra = None
            
        st.markdown('</div>', unsafe_allow_html=True)
    
    with st.container():
        st.markdown('<div class="filter-card">', unsafe_allow_html=True)
        st.markdown("**Configura√ß√µes de Exporta√ß√£o**")
        
        only_member_pk = st.checkbox("Exportar apenas IDs", value=False)
        export_format = st.radio("Formato:", 
                                ["CSV", "Excel"], 
                                horizontal=True)
        st.markdown('</div>', unsafe_allow_html=True)

# ==========================================
# FUN√á√ïES DE PROCESSAMENTO
# ==========================================
def build_query_conditions():
    """Constr√≥i condi√ß√µes WHERE para a query SQL com valida√ß√£o"""
    conditions = []
    
    # Valida√ß√£o de filtros contradit√≥rios
    filter_warnings = []
    
    # Filtro por ID espec√≠fico
    if id_busca and id_busca.strip():
        conditions.append(f"member_pk = '{id_busca}'")
    
    # Filtro por categorias
    if cat_sel:
        cat_list = ', '.join([f"'{c}'" for c in cat_sel])
        conditions.append(f"categoria IN ({cat_list})")
    
    # Filtro por setores
    if setor_sel:
        setor_list = ', '.join([f"'{s}'" for s in setor_sel])
        conditions.append(f"setor IN ({setor_list})")
    
    # Filtro de data de visita (sempre ativo)
    # Adiciona 1 dia ao fim para incluir todo o √∫ltimo dia
    data_fim_visita_ajustada = datetime.combine(data_fim_visita, datetime.max.time())
    conditions.append(f"data_ultima_visita >= '{data_inicio_visita}'")
    conditions.append(f"data_ultima_visita <= '{data_fim_visita_ajustada}'")
    
    # Filtro de data de compra
    if usar_compra and data_inicio_compra and data_fim_compra:
        # Verifica contradi√ß√£o com "apenas sem compra"
        if apenas_sem_compra:
            filter_warnings.append("'Apenas sem compra' e filtro por data de compra s√£o contradit√≥rios")
        
        data_fim_compra_ajustada = datetime.combine(data_fim_compra, datetime.max.time())
        conditions.append(f"data_ultima_compra >= '{data_inicio_compra}'")
        conditions.append(f"data_ultima_compra <= '{data_fim_compra_ajustada}'")
    
    # Filtro de data de cadastro
    if usar_cadastro and data_inicio_cadastro and data_fim_cadastro:
        data_fim_cadastro_ajustada = datetime.combine(data_fim_cadastro, datetime.max.time())
        conditions.append(f"data_cadastro >= '{data_inicio_cadastro}'")
        conditions.append(f"data_cadastro <= '{data_fim_cadastro_ajustada}'")
    
    # Filtro para clientes sem compra
    if apenas_sem_compra:
        conditions.append("data_ultima_compra IS NULL")
    
    # NOVO FILTRO: Funcion√°rios
    if dataset_info['has_flg_funcionario']:
        if filtro_funcionarios == "Apenas funcion√°rios":
            conditions.append("flg_funcionario = 'S'")
        elif filtro_funcionarios == "Excluir funcion√°rios":
            conditions.append("(flg_funcionario = 'N' OR flg_funcionario IS NULL)")
        # "Todos" n√£o adiciona condi√ß√£o
    
    # Filtros de premium (exclusivos - corrigido)
    if dataset_info['has_flg_premium']:
        if apenas_premium:
            # NOVO FILTRO: apenas usu√°rios premium ativos
            conditions.append("flg_premium_ativo = 'S'")
        elif excluir_premium:
            # FILTRO ANTIGO: excluir premium
            conditions.append("(flg_premium_ativo = 'N' OR flg_premium_ativo IS NULL)")
        
        # Valida√ß√£o de filtros premium contradit√≥rios
        if apenas_premium and excluir_premium:
            filter_warnings.append("'Apenas premium' e 'Excluir premium' s√£o contradit√≥rios")
    
    # Exibir warnings se houver
    if filter_warnings:
        st.markdown('<div class="warning-box">', unsafe_allow_html=True)
        st.markdown("**‚ö†Ô∏è Aten√ß√£o aos filtros:**")
        for warning in filter_warnings:
            st.markdown(f"- {warning}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    return " AND ".join(conditions) if conditions else "1=1", filter_warnings

# ==========================================
# AN√ÅLISE AUTOM√ÅTICA (SEMPRE EXECUTA)
# ==========================================
try:
    where_clause, warnings_list = build_query_conditions()
    
    # Cria nova conex√£o DuckDB
    con = duckdb.connect(database=':memory:')
    
    # Query para obter estat√≠sticas dos filtros aplicados
    stats_query = f"""
    WITH filtered AS (
        SELECT * 
        FROM read_parquet('{dataset_info['caminho']}')
        WHERE {where_clause}
    )
    SELECT 
        COUNT(*) as total_registros,
        COUNT(DISTINCT member_pk) as clientes_unicos,
        {f"COUNT(CASE WHEN flg_funcionario = 'S' THEN 1 END) as funcionarios," if dataset_info['has_flg_funcionario'] else "0 as funcionarios,"}
        {f"COUNT(CASE WHEN flg_premium_ativo = 'S' THEN 1 END) as premium" if dataset_info['has_flg_premium'] else "0 as premium"}
    FROM filtered
    """
    
    result = con.execute(stats_query).fetchone()
    
    if result:
        if dataset_info['has_flg_funcionario'] and dataset_info['has_flg_premium']:
            total_filtrado, clientes_unicos, funcionarios, premium = result
        elif dataset_info['has_flg_funcionario']:
            total_filtrado, clientes_unicos, funcionarios, _ = result
            premium = 0
        elif dataset_info['has_flg_premium']:
            total_filtrado, clientes_unicos, _, premium = result
            funcionarios = 0
        else:
            total_filtrado, clientes_unicos, _, _ = result
            funcionarios, premium = 0, 0
    else:
        total_filtrado, clientes_unicos, funcionarios, premium = 0, 0, 0, 0
        
except Exception as e:
    st.error(f"‚ùå Erro na an√°lise dos dados: {str(e)}")
    # Valores padr√£o em caso de erro
    total_filtrado, clientes_unicos, funcionarios, premium = 0, 0, 0, 0
    con = None

# ==========================================
# RESUMO DOS RESULTADOS (APENAS 2 BIG NUMBERS)
# ==========================================
st.markdown("### üìä Resultados")

col1, col2 = st.columns(2)

with col1:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.markdown('<div class="metric-label">Total de Registros</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="big-metric">{total_filtrado:,}</div>', unsafe_allow_html=True)
    
    # Informa√ß√µes adicionais relevantes
    if total_filtrado > 0:
        # Mostra funcion√°rios se o filtro estiver ativo
        if dataset_info['has_flg_funcionario'] and funcionarios > 0:
            perc_funcionarios = (funcionarios / total_filtrado * 100) if total_filtrado > 0 else 0
            st.caption(f"Funcion√°rios: {funcionarios:,} ({perc_funcionarios:.1f}%)")
        
        # Mostra premium se o filtro estiver ativo
        if dataset_info['has_flg_premium'] and premium > 0:
            perc_premium = (premium / total_filtrado * 100) if total_filtrado > 0 else 0
            st.caption(f"Premium: {premium:,} ({perc_premium:.1f}%)")
            
    st.markdown('</div>', unsafe_allow_html=True)

with col2:
    st.markdown('<div class="metric-card">', unsafe_allow_html=True)
    st.markdown('<div class="metric-label">Clientes √önicos</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="big-metric">{clientes_unicos:,}</div>', unsafe_allow_html=True)
    
    # Informa√ß√µes adicionais se desejar
    if total_filtrado > 0 and clientes_unicos > 0:
        duplicados = total_filtrado - clientes_unicos
        if duplicados > 0:
            st.caption(f"{duplicados:,} registros duplicados")
    st.markdown('</div>', unsafe_allow_html=True)

# ==========================================
# PR√â-VISUALIZA√á√ÉO DOS DADOS
# ==========================================
if total_filtrado > 0 and con is not None:
    with st.expander("üëÅÔ∏è **Pr√©-visualiza√ß√£o dos Dados**", expanded=True):
        try:
            # Define colunas para exibi√ß√£o
            base_cols = ['member_pk', 'categoria', 'setor', 'data_ultima_visita', 'data_ultima_compra']
            
            # Adiciona colunas extras se dispon√≠veis
            if 'data_cadastro' in dataset_info['available_columns']:
                base_cols.append('data_cadastro')
            
            if 'flg_premium_ativo' in dataset_info['available_columns']:
                base_cols.append('flg_premium_ativo')
            
            if 'flg_funcionario' in dataset_info['available_columns']:
                base_cols.append('flg_funcionario')
            
            # Prepara query de preview
            cols_str = ', '.join(base_cols)
            preview_query = f"""
            SELECT {cols_str}
            FROM read_parquet('{dataset_info['caminho']}')
            WHERE {where_clause}
            ORDER BY data_ultima_visita DESC
            LIMIT 100
            """
            
            preview_df = con.execute(preview_query).df()
            
            if not preview_df.empty:
                # Configura√ß√µes das colunas para exibi√ß√£o
                column_config = {
                    "member_pk": st.column_config.TextColumn("ID Cliente", width="large"),
                    "categoria": st.column_config.TextColumn("Categoria", width="medium"),
                    "setor": st.column_config.TextColumn("Setor", width="medium"),
                    "data_ultima_visita": st.column_config.DatetimeColumn("√öltima Visita", format="DD/MM/YYYY HH:mm"),
                    "data_ultima_compra": st.column_config.DatetimeColumn("√öltima Compra", format="DD/MM/YYYY HH:mm"),
                }
                
                # Adiciona configura√ß√£o para data_cadastro se existir
                if 'data_cadastro' in preview_df.columns:
                    column_config["data_cadastro"] = st.column_config.DatetimeColumn("Data Cadastro", format="DD/MM/YYYY")
                
                if 'flg_premium_ativo' in preview_df.columns:
                    column_config["flg_premium_ativo"] = st.column_config.TextColumn("Premium", width="small")
                
                if 'flg_funcionario' in preview_df.columns:
                    column_config["flg_funcionario"] = st.column_config.TextColumn("Funcion√°rio", width="small")
                
                # Formata√ß√£o das datas
                date_cols = [col for col in preview_df.columns if 'data_' in col]
                for col in date_cols:
                    preview_df[col] = pd.to_datetime(preview_df[col], errors='coerce')
                
                st.dataframe(
                    preview_df,
                    use_container_width=True,
                    column_config=column_config,
                    hide_index=True
                )
                st.caption(f"Mostrando 100 de {total_filtrado:,} registros (ordenados por √∫ltima visita)")
            else:
                st.info("Nenhum dado para pr√©-visualizar")
                
        except Exception as e:
            st.error(f"Erro na pr√©-visualiza√ß√£o: {str(e)}")
    
    # ==========================================
    # EXPORTA√á√ÉO
    # ==========================================
    st.markdown("### üì§ Exporta√ß√£o")
    
    col_exp1, col_exp2 = st.columns([3, 1])
    
    with col_exp1:
        # Resumo da exporta√ß√£o com informa√ß√µes dos filtros
        export_summary = f"**{total_filtrado:,} registros** ‚Ä¢ **{clientes_unicos:,} clientes √∫nicos**"
        
        # Informa filtros ativos mais relevantes
        active_filters = []
        if apenas_sem_compra:
            active_filters.append("sem compra")
        
        if dataset_info['has_flg_funcionario'] and filtro_funcionarios != "Todos":
            active_filters.append(filtro_funcionarios.lower())
        
        if dataset_info['has_flg_premium']:
            if apenas_premium:
                active_filters.append("premium ativos")
            elif excluir_premium:
                active_filters.append("sem premium")
        
        if active_filters:
            export_summary += f" ‚Ä¢ **Filtros:** {', '.join(active_filters)}"
        
        # Adiciona estat√≠sticas relevantes
        stats_details = []
        if dataset_info['has_flg_funcionario'] and funcionarios > 0:
            stats_details.append(f"{funcionarios:,} funcion√°rios")
        
        if dataset_info['has_flg_premium'] and premium > 0:
            stats_details.append(f"{premium:,} premium")
        
        if stats_details:
            export_summary += f" ‚Ä¢ {' ‚Ä¢ '.join(stats_details)}"
        
        st.info(export_summary)
    
    with col_exp2:
        export_disabled = total_filtrado > 1000000 and export_format == "Excel"
        
        if export_disabled:
            st.warning("Excel limitado a 1M registros")
        else:
            if st.button("üöÄ Gerar Arquivo", type="primary", use_container_width=True):
                with st.spinner("Preparando exporta√ß√£o..."):
                    try:
                        # Query completa
                        select_cols = "member_pk" if only_member_pk else "*"
                        export_query = f"""
                        SELECT {select_cols}
                        FROM read_parquet('{dataset_info['caminho']}')
                        WHERE {where_clause}
                        ORDER BY data_ultima_visita DESC
                        """
                        
                        export_df = con.execute(export_query).df()
                        
                        # Gera arquivo
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        
                        if export_format == "Excel":
                            import io
                            buffer = io.BytesIO()
                            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                export_df.to_excel(writer, index=False, sheet_name='Clientes')
                            buffer.seek(0)
                            file_data = buffer.getvalue()
                            file_name = f"clientes_{timestamp}.xlsx"
                            mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        else:
                            file_data = export_df.to_csv(index=False, sep=';', encoding='utf-8').encode('utf-8')
                            file_name = f"clientes_{timestamp}.csv"
                            mime_type = "text/csv"
                        
                        # Bot√£o de download
                        st.download_button(
                            label=f"üì• Baixar {export_format} ({len(export_df):,} registros)",
                            data=file_data,
                            file_name=file_name,
                            mime=mime_type,
                            use_container_width=True
                        )
                        
                        st.success("‚úÖ Arquivo gerado com sucesso!")
                        
                    except Exception as e:
                        st.error(f"‚ùå Erro na exporta√ß√£o: {str(e)}")
    
    # Fecha a conex√£o
    if con:
        con.close()

elif con is not None:
    st.warning("‚ö†Ô∏è Nenhum registro encontrado com os filtros aplicados.")
    
    # Mostra mensagens √∫teis
    if warnings_list:
        st.info("üìù **Poss√≠veis causas:**")
        for warning in warnings_list:
            st.write(f"- {warning}")
    else:
        st.info("üí° Tente ajustar os crit√©rios de filtragem.")
    
    if con:
        con.close()

# ==========================================
# RODAP√â
# ==========================================
st.markdown("---")
st.caption(f"üìä Base de dados: {dataset_info['num_rows']:,} registros ‚Ä¢ √öltima atualiza√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
